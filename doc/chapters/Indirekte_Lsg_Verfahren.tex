\chapter{Lösen des Optimalsteuerungsproblem mit indirekten Lösungsverfahren}

Um das Optimalsteuerungsproblem \ref{prob:MaxRF} mit indirekten Lösungsverfahren lösen zu können, muss dieses zunächst auf ein Zweipunkt-Randwertproblem umgestellt werden.

\begin{problem}[Zweipunkt-Randwertproblem]\label{prob:ZweiRand}
Seien $G : [t_0,t_f] \times \R^{n_Z} \to \R^{n_Z}$ und $R : \R^{n_Z} \times \R^{n_Z} \to \R^{n_Z}$ gegeben. Gesucht ist eine Lösung $Z$ des Randwertproblems
\begin{align}
\dot{Z}(t) &= G(t,Z(t),U(t)) \\
R(Z(t_0),Z(t_f)) &= 0_{n_Z}
\end{align}
im Intervall $[t_0,t_f]$.
\end{problem}

Jedoch behandelt das Zweipunkt-Randwertproblem keine Bedingungen wie die Beschränkung des Staudrucks $q(v(t),h(t)) \leq q_{\max}$, wie in Problem \ref{prob:MaxRF} gefordert. Untersuchungen der Ergebnisse aus den Versuchen \ref{kap:Versuch11}, \ref{kap:Versuch31} und  \ref{kap:Versuch41} haben gezeigt, dass diese zu keinem Zeitpunkt den maximalen Wert $q_{\max}$ der Beschränkung erreicht haben. Aus Vereinfachungsgründen, wird diese Beschränkung deshalb in diesem Kapitel nicht weiter berücksichtigt.



















\section{Aufstellen des Randwertproblems}
Mit den Optimalitätsbedingungen des Minimumprinzips von Pontryagin lässt sich das Steuerungsproblem in ein Randwertproblem überführen, welches aus den beiden Funktionen $G(t,Z(t),U(t))$ und $R(Z(t_0),Z(t_f)) = 0_{n_Z}$ besteht:
\begin{itemize}
\item Für $G(t,Z(t),U(t))$ ergibt sich
\begin{equation}
\dot{Z}(t) = G(t,Z(t),U(t)) = \begin{pmatrix}
\dot{h}(t),\dot{\gamma}(t),\dot{x}(t),\dot{v}(t),\dot{\lambda}_1(t),\dot{\lambda}_2(t),\dot{\lambda}_3(t),\dot{\lambda}_4(t)
\end{pmatrix}^T
\end{equation}
und für die Ableitung
\begin{equation}
\dfrac{\partial G(t,Z(t),U(t))}{\partial Z} = \begin{pmatrix}
0 & J_G^{(1,2)} & 0 & J_G^{(1,4)} & 0 & 0 & 0 & 0 \\ 
J_G^{(2,1)} & J_G^{(2,2)} & 0 & J_G^{(2,4)} & 0 & 0 & 0 & 0 \\ 
0 & J_G^{(3,2)} & 0 & J_G^{(3,4)} & 0 & 0 & 0 & 0 \\ 
J_G^{(4,1)} & J_G^{(4,2)} & 0 & J_G^{(4,4)} & 0 & 0 & 0 & 0 \\
J_G^{(5,1)} & 0 & 0 & J_G^{(5,4)} & 0 & J_G^{(5,6)} & 0 & J_G^{(5,8)} \\
0 & J_G^{(6,2)} & 0 & J_G^{(6,4)} & J_G^{(6,5)} & J_G^{(6,6)} & J_G^{(6,7)} & J_G^{(6,8)} \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
J_G^{(8,1)} & J_G^{(8,2)} & 0 & J_G^{(8,4)} & J_G^{(8,5)} & J_G^{(8,6)} & J_G^{(8,7)} & J_G^{(8,8)}
\end{pmatrix}
\end{equation}
mit:
\begin{align}
J_G^{(1,2)} &= v(t) \cos(\gamma(t)) \\
J_G^{(1,4)} &= \sin(\gamma(t)) \\
J_G^{(2,1)} &= - \dfrac{F \alpha \beta e^{-\beta h(t)} v(t) C_L(t)}{2m} \\
J_G^{(2,2)} &= \dfrac{g \sin(\gamma(t))}{v(t)} \\
J_G^{(2,4)} &= \dfrac{F \alpha e^{-\beta h(t)} C_L(t)}{2m} + \dfrac{g \cos(\gamma(t))}{v^2(t)} \\
J_G^{(3,2)} &= - v(t) \sin(\gamma(t)) \\
J_G^{(3,4)} &= \cos(\gamma(t)) \\
J_G^{(4,1)} &= \dfrac{(C_{D_0} + k C_L^2(t)) F \alpha \beta e^{-\beta h(t)} v^2(t)}{2m} \\
J_G^{(4,2)} &= - g \cos(\gamma(t)) \\
J_G^{(4,4)} &= -\dfrac{(C_{D_0} + k C_L^2(t)) F \alpha e^{-\beta h(t)} v(t)}{m}  \\
J_G^{(5,1)} &= \dfrac{\alpha \beta^2 F e^{-\beta h(t)} C_L(t) v(t) \lambda_2(t)}{2m} - \dfrac{(C_{D_0}+k C_L^2(t)) \alpha \beta^2 F e^{-\beta h(t)} v^2(t) \lambda_4(t)}{2m} \\
J_G^{(5,4)} &= - \dfrac{\alpha \beta F e^{-\beta h(t)} C_L(t) \lambda_2(t)}{2m} + \dfrac{(C_{D_0}+k C_L^2(t)) \alpha \beta F e^{-\beta h(t)} v(t) \lambda_4(t)}{m} \\
J_G^{(5,6)} &= - \dfrac{\alpha \beta F e^{-\beta h(t)} C_L(t) v(t)}{2m}\\
J_G^{(5,8)} &= \dfrac{(C_{D_0}+k C_L^2(t)) \alpha \beta F e^{-\beta h(t)} v^2(t)}{2m} \\
J_G^{(6,2)} &= -\sin(\gamma(t)) v(t) \lambda_1(t) + \dfrac{g \cos(\gamma(t)) \lambda_2(t)}{v(t)} - \cos(\gamma(t)) v(t) \lambda_3(t) + \sin(\gamma(t)) g \lambda_4(t) \\
J_G^{(6,4)} &= \cos(\gamma(t)) \lambda_1(t) - \dfrac{g \sin(\gamma(t)) \lambda_2(t)}{v^2(t)} - \sin(\gamma(t)) \lambda_3(t) \\
J_G^{(6,5)} &= \cos(\gamma(t)) v(t) \\
J_G^{(6,6)} &= \dfrac{g \sin(\gamma(t))}{v(t)} \\
J_G^{(6,7)} &= - \sin(\gamma(t)) v(t) \\
J_G^{(6,8)} &= - \cos(\gamma(t)) g \\
J_G^{(8,1)} &= -\dfrac{F \alpha \beta e^{-\beta h(t)} C_L(t) \lambda_2(t)}{2m}  + \dfrac{(C_{D_0} + k C_L^2(t)) F \alpha \beta e^{-\beta h(t)} v(t) \lambda_4(t)}{m} \\
J_G^{(8,2)} &= \cos(\gamma(t)) \lambda_1(t) - \dfrac{g \sin(\gamma(t)) \lambda_2(t)}{v^2(t)} - \sin(\gamma(t)) \lambda_3(t) \\
J_G^{(8,4)} &= - \dfrac{2 g \cos(\gamma(t)) \lambda_2(t)}{v^3(t)} - \dfrac{(C_{D_0} + k C_L^2(t)) F \alpha e^{-\beta h(t)} \lambda_4(t)}{m} \\
J_G^{(8,5)} &= \sin(\gamma(t)) \\
J_G^{(8,6)} &= \dfrac{F \alpha e^{-\beta h(t)} C_L(t)}{2m} + \dfrac{g \cos(\gamma(t))}{v^2(t)} \\
J_G^{(8,7)} &= \cos(\gamma(t)) \\
J_G^{(8,8)} &= - \dfrac{(C_{D_0} + k C_L^2(t)) F \alpha e^{-\beta h(t)} v(t)}{m} 
\end{align}
%
\item Für $R(Z(t_0),Z(t_f)) = 0_{n_Z}$ müssen zunächst die Endbedingungen mit gebildet aus
\begin{align*}
X_i(t_f) &= c_i & & (i=1,...,r=2) \\
\lambda_i(t_f) &= \lambda_0 g_{X_i}(X^{\ast}(t_f)) & &(i=r+1,...,n=4)
\end{align*}
mit
\begin{align*}
c &= \begin{pmatrix} h_f & \gamma_f \end{pmatrix} \\
g_{X}(X^{\ast}(t_f)) &= \begin{pmatrix} 0 & 0 & -1 & 0 \end{pmatrix}
\end{align*}
gebildet werden. Es ergibt sich dann
\begin{equation}
R(Z(t_0),Z(t_f)) = 0_{n_Z} = \begin{pmatrix}
h(t_0) - h_0 \\ 
\gamma(t_0) - \gamma_0 \\
x(t_0) - x_0 \\ 
v(t_0) - v_0 \\ 
h(t_f) - h_f \\ 
\gamma(t_f) - \gamma_f \\
\lambda_3(t_f) + \lambda_0 \\ 
\lambda_4(t_f) - 0
\end{pmatrix}
\end{equation}
mit 
\begin{equation}
\dfrac{d R(Z(t_0),Z(t_f))}{d Z(t_0)} = \begin{pmatrix}
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0
\end{pmatrix}
\end{equation}
\begin{equation}
\dfrac{d R(Z(t_0),Z(t_f))}{d Z(t_f)} = \begin{pmatrix}
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}
\end{equation}
\end{itemize}





















\section{Algorithmus Einfachschiessverfahren}
Für eine gegebene Startschätzung $\eta$ des Anfangswerts $y(a)$ besitze das Anfangswertproblem
\[y'(t) = g(t, y(t)) \ \ \ \ y(a) = \eta\]
die Lösung $y(t;\eta)$ auf $[a,b]$. Damit $y(t;\eta)$ auch die Randbedingung erfüllt, muss 
\begin{equation}\label{func:SchiessF}
F(\eta) := r(y(a;\eta), y(b;\eta)) = r(\eta, y(b;\eta)) = 0_{n_y}
\end{equation}
gelten. Gleichung \ref{func:SchiessF} ist also ein \textbf{nichtlineares Gleichungssystem} für die Funktion $F$. Anwendung des Newtonverfahrens führt auf das sogenannte Einfachschießverfahren:

\begin{definition}[Algorithmus Einfachschießverfahren]\label{algo:EinfSchiess}
Initialisierung: Wähle Startschätzung $\eta^{[0]} \in \R^{n_y}$ und setze $i = 0$:
\begin{enumerate}
\item Löse das Anfangswertproblem \[y'(t) = g(t, y(t)) \ \ \ \ y(a) = \eta^{[i]} \ \ \ \ (a \leq t \leq b)\] zur Berechnung von $F(\eta^{[i]})$ und berechne die Jacobimatrix \[F'(\eta^{[i]}) = r'_{y_a} (\eta^{[i]}, y(b;\eta^{[i]})) + r'_{y_b}(\eta^{[i]}, y(b;\eta^{[i]})) \cdot S(b)\] wobei $S$ Lösung der Sensitivitäts-Differentialgleichung \[S'(t) = g'_y(t, y(t;\eta^{[i]})) \cdot S(t) \ \ \ \ S(a) = I_{n_y \times n_y}\] ist.
%
\item Ist $F(\eta^{[i]}) = 0_{n_y}$ (oder ist ein anderes Abbruchkriterium) erfüllt, \textbf{STOP!}
%
\item Berechne die Newton-Richtung $d^{[i]}$ als Lösung des linearen Gleichungssystems \[F'(\eta^{[i]})d = -F(\eta^{[i]})\]
%
\item Setze $\eta^{[i+1]} = \eta^{[i]} + d^{[i]}$ und $i=i+1$ und gehe zu 1.).
\end{enumerate}
\end{definition}

Die Ableitung $F'(\eta^{[i]})$ in Schritt 2.) des Einfachschießverfahrens \ref{algo:EinfSchiess} kann alternativ
durch \textbf{finite Differenzen} approximiert werden:
\[\dfrac{\partial}{\partial \eta_j} F(\eta) \approx \dfrac{F(\eta + h e_j) - F(\eta)}{h} \ \ \ \ (j=1,...,n_y)\]
mit $e_j = j$-ter Einheitsvektor. Dieser Ansatz erfordert das Lösen von $n_y$ Anfangswertproblemen!

